What linguistic features can improve statistical machine translation (MT)? This is a fundamental question for the discipline, particularly as it pertains to improving the best systems we have. Further: â¢ Do syntax-based translation systems have unique and effective levers to pull when designing new features? â¢ Can large numbers of feature weights be learned efficiently and stably on modest amounts of data? In this paper, we address these questions by experimenting with a large number of new features. We add more than 250 features to improve a syntax- based MT systemâalready the highest-scoring single system in the NIST 2008 ChineseEnglish common-data trackâby +1.1 Bï¬ï¥ïµ. We also add more than 10,000 features to Hiero (Chiang, 2005) and obtain a +1.5 Bï¬ï¥ïµ improvement. âThis research was supported in part by DARPA contract HR001106-C-0022 under subcontract to BBN Technologies. Many of the new features use syntactic information, and in particular depend on information that is available only inside a syntax-based translation model. Thus they widen the advantage that syntax- based models have over other types of models. The models are trained using the Margin Infused Relaxed Algorithm or MIRA (Crammer et al., 2006) instead of the standard minimum-error-rate training or MERT algorithm (Och, 2003). Our results add to a growing body of evidence (Watanabe et al., 2007; Chiang et al., 2008) that MIRA is preferable to MERT across languages and systems, even for very large-scale tasks.
