It is well-known that constituency parsing models designed for English often do not generalize easily to other languages and treebanks.1 Explanations for this phenomenon have included the relative informativeness of lexicalization (Dubey and Keller, 2003; Arun and Keller, 2005), insensitivity to morphology (Cowan and Collins, 2005; Tsarfaty and Simaâan, 2008), and the effect of variable word order (Collins et al., 1999). Certainly these linguistic factors increase the difficulty of syntactic disambiguation. Less frequently studied is the interplay among language, annotation choices, and parsing model design (Levy and Manning, 2003; KuÂ¨ bler, 2005). 1 The apparent difficulty of adapting constituency models to non-configurational languages has been one motivation for dependency representations (HajicË and ZemaÂ´nek, 2004; Habash and Roth, 2009). To investigate the influence of these factors, we analyze Modern Standard Arabic (henceforth MSA, or simply âArabicâ) because of the unusual opportunity it presents for comparison to English parsing results. The Penn Arabic Treebank (ATB) syntactic guidelines (Maamouri et al., 2004) were purposefully borrowed without major modification from English (Marcus et al., 1993). Further, Maamouri and Bies (2004) argued that the English guidelines generalize well to other languages. But Arabic contains a variety of linguistic phenomena unseen in English. Crucially, the conventional orthographic form of MSA text is unvocalized, a property that results in a deficient graphical representation. For humans, this characteristic can impede the acquisition of literacy. How do additional ambiguities caused by devocalization affect statistical learning? How should the absence of vowels and syntactic markers influence annotation choices and grammar development? Motivated by these questions, we significantly raise baselines for three existing parsing models through better grammar engineering. Our analysis begins with a description of syntactic ambiguity in unvocalized MSA text (Â§2). Next we show that the ATB is similar to other tree- banks in gross statistical terms, but that annotation consistency remains low relative to English (Â§3). We then use linguistic and annotation insights to develop a manually annotated grammar for Arabic (Â§4). To facilitate comparison with previous work, we exhaustively evaluate this grammar and two other parsing models when gold segmentation is assumed (Â§5). Finally, we provide a realistic eval uation in which segmentation is performed both in a pipeline and jointly with parsing (Â§6). We quantify error categories in both evaluation settings. To our knowledge, ours is the first analysis of this kind for Arabic parsing.
